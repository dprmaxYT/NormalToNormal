<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>conversor de normales</title>
    <link rel="stylesheet" href="styles/indexstyle.css">
    <link rel="stylesheet" href="styles/menu.css">
    <link rel="stylesheet" href="styles/style.css">
</head>
<body>
    <div class="menu-container">
        <div class="menu menua">
            <button onclick="window.location.href = 'convertidores/gl-to-dx/gl-to-dx.html'">OpenGL a DirectX</button>
        </div>
        <div class="menuimg">
            <img class="icon" src="resources/icon.png" onclick="location.href='https://itsdpr.webflow.io';">
        </div>
        <div class="menu">
            <button onclick="window.location.href = 'convertidores/dx-to-gl/dx-to-gl.html'">DirectX a OpenGL</button>
        </div>
    </div>
    <p style="color: rgba(0, 0, 0, 0);">que miras bro</p>
    <div class="info">
        <p>Bienvenido a mi conversor de Mapas de normales</p>
        <p id="texto">Esta pagina NO usa galletas, por que son para comer, no para internet, a si que aqui estas seguro bro :)</p>
        <p id="texto">este servicio es 100% Gratuito y no tiene anuncios</p>
        <p id="texto">Te recomiendo mirar en la parte de abajo de los convertidores, hay informacion util ;)</p>
    </div>
    <div class="info">
        <h1>Los Mapas de normalees en CG</h1>
        <a>Los mapas de normales, una herramienta esencial en la creación de gráficos por ordenador, desempeñan un papel crucial en la simulación de superficies detalladas y realistas en entornos virtuales. En este artículo, vamos a sumergirnos en los detalles de qué son los mapas de normales, cómo funcionan y cómo se implementan en una variedad de API gráficas, incluyendo DirectX, OpenGL, Vulkan y Metal.</a>
        <p>
            <b style="font-size: larger;">¿Qué son los Mapas de Normales?</b>
        </p>
        <a>Los mapas de normales, conocidos también como mapas de bump o bump maps, son texturas especiales utilizadas en gráficos por ordenador para codificar información sobre la dirección de la superficie de un objeto en cada punto. En esencia, estas texturas almacenan vectores normales en lugar de colores. Estos vectores representan la dirección en la que la superficie está orientada en cada punto, lo que permite simular la apariencia de detalles geométricos sin necesidad de aumentar la cantidad de polígonos en el modelo 3D.</a>
        <p>
            <b style="font-size: larger;">Funcionamiento Detallado de los Mapas de Normales</b>
        </p>
        <a>Cuando se aplica un mapa de normales a un objeto en un entorno 3D, los vectores normales almacenados en la textura se utilizan para ajustar la dirección de la superficie en cada punto. Esto se logra mediante la modificación de la normal del vértice en función de los valores almacenados en la textura. El resultado es una ilusión visual de que la superficie tiene más detalles geométricos de los que realmente tiene, lo que añade profundidad y realismo a la escena renderizada.</a>
        <h2>Las APIs Graficas</h2>
        <p>
            <b style="font-size: larger;">DirectX</b>
        </p>
        <a>Desarroyado por Microsoft. En DirectX, los mapas de normales son fundamentales para mejorar la calidad visual de los objetos en una escena 3D. A nivel más profundo, su implementación implica varios pasos clave:</a>
        <p>
            <b>1. Carga de texturas</b>
        </p>
        <a>Los mapas de normales se cargan desde archivos de textura utilizando las funciones proporcionadas por DirectX. Estos archivos contienen información sobre la dirección de la superficie en cada punto de un objeto.</a>
        <p>
            <b>2. Aplicación de los Mapas de Normales</b>
        </p>
        <a>Una vez cargados, los mapas de normales se aplican a los objetos como texturas adicionales. Esto se logra configurando los estados de textura apropiados en el dispositivo gráfico de DirectX.</a>
        <p>
            <b>3. Procesamiento en el vertex shader</b>
        </p>
        <a> Durante el proceso de renderizado, los vértices de los objetos se procesan en el Vertex Shader. Aquí, los vectores normales de los vértices se ajustan en función de los valores almacenados en el mapa de normales. Este ajuste puede implicar la transformación de los vectores normales del espacio del objeto al espacio de la cámara o del ojo, según las necesidades de la aplicación.</a>
        <p>
            <b>4. Interpolación y Pase al Fragment Shader</b>
        </p>
        <a>Después de procesarse en el Vertex Shader, los datos interpolados se pasan al Fragment Shader. Aquí, los fragmentos de píxeles resultantes de la rasterización se procesan individualmente. En el Fragment Shader, se realizan cálculos adicionales basados en los datos de los mapas de normales, como el cálculo de la iluminación especular o la mezcla de texturas adicionales para simular detalles superficiales.</a>
        <p>
            <b>5. Renderizado Final</b>
        </p>
        <a>Finalmente, los píxeles procesados por el Fragment Shader se combinan para generar el color final de cada píxel en el búfer de fotogramas. Durante este proceso, se tiene en cuenta la contribución de los mapas de normales para determinar la apariencia visual final de los objetos en la escena.</a>
        <p>
            <b style="font-size: larger;">OpenGL</b>
        </p>
        <a>En OpenGL, los mapas de normales desempeñan un papel esencial en la mejora de la calidad visual de los objetos en una escena 3D. A nivel más profundo, su implementación implica varios pasos clave:</a>
        <p>
            <b>1. Carga de Texturas</b>
        </p>
        <a>Los mapas de normales se cargan desde archivos de textura utilizando las funciones proporcionadas por OpenGL. Estos archivos contienen información sobre la dirección de la superficie en cada punto de un objeto.</a>
        <p>
            <b>2. Aplicación de los Mapas de Normales</b>
        </p>
        <a>Una vez cargados, los mapas de normales se aplican a los objetos como texturas adicionales. Esto se logra configurando los estados de textura apropiados en el contexto de renderizado de OpenGL.</a>
        <p>
            <b>3. Procesamiento en el Vertex Shader</b>
        </p>
        <a>Durante el proceso de renderizado, los vértices de los objetos se procesan en el Vertex Shader. Aquí, los vectores normales de los vértices se ajustan en función de los valores almacenados en el mapa de normales. Este ajuste puede implicar la transformación de los vectores normales del espacio del objeto al espacio de la cámara o del ojo, según las necesidades de la aplicación.</a>
        <p>
            <b>4. Interpolación y Pase al Fragment Shader</b>
        </p>
        <a>Después de procesarse en el Vertex Shader, los datos interpolados se pasan al Fragment Shader. Aquí, los fragmentos de píxeles resultantes de la rasterización se procesan individualmente. En el Fragment Shader, se realizan cálculos adicionales basados en los datos de los mapas de normales, como el cálculo de la iluminación especular o la mezcla de texturas adicionales para simular detalles superficiales.</a>
        <p>
            <b>5. Renderizado Final</b>
        </p>
        <a>Finalmente, los píxeles procesados por el Fragment Shader se combinan para generar el color final de cada píxel en el búfer de fotogramas. Durante este proceso, se tiene en cuenta la contribución de los mapas de normales para determinar la apariencia visual final de los objetos en la escena.</a>
        <p>
            <b style="font-size: larger;">Vulkan</b>
        </p>
        <a>En Vulkan, los mapas de normales son esenciales para mejorar la calidad visual de los objetos en una escena 3D. A nivel más profundo, su implementación implica varios pasos clave:</a>
        <p>
            <b>1. Inicialización de Vulkan</b>
        </p>
        <a>Antes de cargar y utilizar mapas de normales, es necesario inicializar Vulkan, creando instancias, dispositivos lógicos y configurando el contexto de renderizado.</a>
        <p>
            <b>2. Creación de Buffers y Texturas</b>
        </p>
        <a>Se deben crear buffers y texturas en Vulkan para almacenar los datos de los mapas de normales. Esto puede implicar la creación de buffers de vértices y texturas 2D utilizando la API Vulkan.</a>
        <p>
            <b>3. Carga de Mapas de Normales</b>
        </p>
        <a>Los mapas de normales se cargan desde archivos utilizando bibliotecas de carga de imágenes como STB Image o libpng, y luego se transfieren a buffers de textura en Vulkan.</a>
        <p>
            <b>4. Aplicación de los Mapas de Normales</b>
        </p>
        <a>Una vez cargados, los mapas de normales se aplican a los objetos como texturas adicionales. Esto se logra mediante la configuración de los estados de textura en los shaders de Vulkan.</a>
        <p>
            <b>5. Procesamiento en el Shader de Vértices</b>
        </p>
        <a>En el Shader de Vértices de Vulkan, se realizan cálculos para transformar los vértices y ajustar los vectores normales en función de los datos de los mapas de normales.</a>
        <p>
            <b>6. Interpolación y Pase al Shader de Fragmentos</b>
        </p>
        <a>Los datos interpolados se pasan al Shader de Fragmentos, donde se procesan individualmente los fragmentos de píxeles resultantes de la rasterización. Aquí, se realizan cálculos adicionales basados en los datos de los mapas de normales para simular detalles superficiales.</a>
        <p>
            <b>7. Renderizado Final</b>
        </p>
        <a>Finalmente, los píxeles procesados se combinan para generar el color final de cada píxel en el búfer de fotogramas, teniendo en cuenta la contribución de los mapas de normales para determinar la apariencia visual final de los objetos en la escena.</a>
        <p>
            <b style="font-size: larger;">Metal</b>
        </p>
        <a>En Metal, los mapas de normales son fundamentales para mejorar la calidad visual de los objetos en una escena 3D. A nivel más profundo, su implementación implica varios pasos clave:</a>
        <p>
            <b>1. Configuración de Metal</b>
        </p>
        <a>Antes de utilizar mapas de normales, se debe configurar Metal creando un dispositivo MTLDevice y configurando un contexto de renderizado MTLRenderContext.</a>
        <p>
            <b>2. Creación de Texturas</b>
        </p>
        <a>Se deben crear texturas en Metal para almacenar los datos de los mapas de normales. Esto implica la creación de texturas de 2D utilizando la API Metal.</a>
        <p>
            <b>3. Carga de Mapas de Normales</b>
        </p>
        <a>Los mapas de normales se cargan desde archivos utilizando las bibliotecas de carga de imágenes adecuadas, y luego se transfieren a las texturas de Metal.</a>
        <p>
            <b>4. Aplicación de los Mapas de Normales</b>
        </p>
        <a>Una vez cargados, los mapas de normales se aplican a los objetos como texturas adicionales en los shaders de Metal.</a>
        <p>
            <b>5. Procesamiento en el Shader de Vértices</b>
        </p>
        <a>En el Shader de Vértices de Metal, se realizan cálculos para transformar los vértices y ajustar los vectores normales en función de los datos de los mapas de normales.</a>
        <p>
            <b>6. Interpolación y Pase al Shader de Fragmentos</b>
        </p>
        <a>Los datos interpolados se pasan al Shader de Fragmentos, donde se procesan individualmente los fragmentos de píxeles resultantes de la rasterización. Aquí, se realizan cálculos adicionales basados en los datos de los mapas de normales para simular detalles superficiales.</a>
        <p>
            <b>7. Renderizado Final</b>
        </p>
        <a>Finalmente, los píxeles procesados se combinan para generar el color final de cada píxel en el búfer de fotogramas, teniendo en cuenta la contribución de los mapas de normales para determinar la apariencia visual final de los objetos en la escena.</a>
        <p>
            <b style="font-size: larger;">WebGL</b>
        </p>
        <a>Desarroyado por Apple. En WebGL, los mapas de normales juegan un papel crucial en la mejora de la calidad visual de los objetos en una escena 3D. A nivel más profundo, su implementación implica varios pasos clave:</a>
        <p>
            <b>1. Configuración de WebGL</b>
        </p>
        <a>Antes de utilizar mapas de normales, se debe configurar WebGL creando un contexto de renderizado WebGL y cargando shaders y programas de sombreado adecuados.</a>
        <p>
            <b>2. Creación de Texturas</b>
        </p>
        <a>Se deben crear texturas en WebGL para almacenar los datos de los mapas de normales. Esto implica la creación de texturas de 2D utilizando las funciones proporcionadas por WebGL.</a>
        <p>
            <b>3. Carga de Mapas de Normales</b>
        </p>
        <a>Los mapas de normales se cargan desde archivos utilizando las herramientas de carga de texturas adecuadas en JavaScript, y luego se transfieren a las texturas en WebGL.</a>
        <p>
            <b>4. Aplicación de los Mapas de Normales</b>
        </p>
        <a>Una vez cargados, los mapas de normales se aplican a los objetos como texturas adicionales en los shaders de WebGL.</a>
        <p>
            <b>5. Procesamiento en el Shader de Vértices</b>
        </p>
        <a>En el Shader de Vértices de WebGL, se realizan cálculos para transformar los vértices y ajustar los vectores normales en función de los datos de los mapas de normales.</a>
        <p>
            <b>6. Interpolación y Pase al Shader de Fragmentos</b>
        </p>
        <a>Los datos interpolados se pasan al Shader de Fragmentos, donde se procesan individualmente los fragmentos de píxeles resultantes de la rasterización. Aquí, se realizan cálculos adicionales basados en los datos de los mapas de normales para simular detalles superficiales.</a>
        <p>
            <b>7. Renderizado Final</b>
        </p>
        <a>Finalmente, los píxeles procesados se combinan para generar el color final de cada píxel en el búfer de fotogramas, teniendo en cuenta la contribución de los mapas de normales para determinar la apariencia visual final de los objetos en la escena.</a>
        
        <h1>Comparación de APIs Gráficas</h1>

        <h2>DirectX</h2>
        <ul>
            <li>Ampliamente utilizado en el ecosistema de juegos de Windows.</li>
            <li>Herramientas de desarrollo maduras y bien documentadas.</li>
            <li>Soporte completo para todas las versiones de Windows.</li>
        </ul>
    
        <h2>OpenGL</h2>
        <ul>
            <li>Multiplataforma, compatible con Windows, macOS, Linux y más.</li>
            <li>Gran base de usuarios y amplio soporte en la industria.</li>
            <li>API madura con una amplia gama de características y extensiones.</li>
        </ul>
    
        <h2>Vulkan</h2>
        <ul>
            <li>API de bajo nivel que ofrece un mayor control sobre el hardware.</li>
            <li>Eficiente y escalable, adecuado para aplicaciones con alto rendimiento.</li>
            <li>Multiplataforma, con soporte en Windows, Linux, Android y más.</li>
        </ul>
    
        <h2>Metal</h2>
        <ul>
            <li>API optimizada para dispositivos Apple, ofreciendo un rendimiento excepcional en iOS y macOS.</li>
            <li>Diseñada para integrarse perfectamente con las tecnologías de Apple, como Swift y Xcode.</li>
            <li>Herramientas de desarrollo de alta calidad y soporte directo de Apple.</li>
        </ul>
    
        <h2>WebGL</h2>
        <ul>
            <li>Basada en OpenGL ES, permite gráficos 3D en navegadores web sin necesidad de plugins.</li>
            <li>Permite el desarrollo de aplicaciones 3D multiplataforma directamente en el navegador.</li>
            <li>Amplia compatibilidad con la mayoría de los navegadores web modernos.</li>
        </ul>
    
        <h2>Mantle</h2>
        <ul>
            <li>API de bajo nivel desarrollada por AMD para optimizar el rendimiento gráfico en hardware Radeon.</li>
            <li>Ofrece un control directo sobre la GPU, permitiendo una programación más eficiente.</li>
            <li>Dirigida principalmente a desarrolladores de videojuegos que buscan un rendimiento óptimo en hardware AMD.</li>
        </ul>
    
        <h2>Glide</h2>
        <ul>
            <li>API gráfica desarrollada por 3dfx Interactive.</li>
            <li>Fue ampliamente utilizada en la década de 1990 para el desarrollo de videojuegos en PC.</li>
            <li>Proporcionaba un rendimiento excepcional en hardware 3dfx Voodoo.</li>
        </ul>
    
        <h2>Comparación</h2>
        <p>
            <b>DirectX:</b> Ideal para desarrolladores centrados en la plataforma Windows y que buscan una solución bien soportada.
        </p>
        <p>
            <b>OpenGL:</b> Una opción sólida para aplicaciones multiplataforma que requieren un amplio soporte de hardware.
        </p>
        <p>
            <b>Vulkan:</b> La elección preferida para aplicaciones que requieren un rendimiento máximo y un control total sobre el hardware gráfico.
        </p>
        <p>
            <b>Metal:</b> La mejor opción para desarrolladores centrados en la plataforma de Apple y que buscan un rendimiento óptimo en dispositivos iOS y macOS.
        </p>
        <p>
            <b>WebGL:</b> Perfecto para aplicaciones 3D que necesitan ejecutarse en navegadores web y alcanzar una amplia audiencia de usuarios.
        </p>
        <p>
            <b>Mantle:</b> Especialmente útil para desarrolladores que buscan un rendimiento óptimo en hardware AMD Radeon y un control directo sobre la GPU.
        </p>
        <p>
            <b>Glide:</b> Utilizada en la década de 1990 para el desarrollo de videojuegos en PC, proporcionaba un rendimiento excepcional en hardware 3dfx Voodoo.
        </p>
    </div>
</body>
</html>
